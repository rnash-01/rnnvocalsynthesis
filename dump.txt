def calculate_gradients(self, Y, t, cache):
    # Get all cache elements
    input_and_output = cache["input_and_output"]
    pre_forget = cache["pre_forget"]
    forget = cache["forget"]
    pre_in_gate = cache["pre_in_gate"]
    in_gate = cache["in_gate"]
    pre_remember = cache["pre_remember"]
    remember = cache["remember"]
    pre_select = cache["pre_select"]
    select = cache["select"]
    state_multiplied = cache["state_multiplied"]
    state_added = cache["state_added"]
    state_tanh = cache["state_tanh"]
    predictions = cache["predictions"]


    # Get parameters
    weights_forget = self.parameters["weights_forget"]
    weights_in_gate = self.parameters["weights_in_gate"]
    weights_remember = self.parameters["weights_remember"]
    weights_select = self.parameters["weights_select"]

    biases_forget = self.parameters["biases_forget"]
    biases_in_gate = self.parameters["biases_in_gate"]
    biases_remember = self.parameters["biases_remember"]
    biases_select = self.parameters["biases_select"]

    # Set up gradient matrices
    dWf = np.zeros(weights_forget.shape)
    dWi = np.zeros(weights_in_gate.shape)
    dWr = np.zeros(weights_remember.shape)
    dWs = np.zeros(weights_remember.shape)

    dbf = np.zeros(biases_forget.shape)
    dbi = np.zeros(biases_in_gate.shape)
    dbr = np.zeros(biases_remember.shape)
    dbs = np.zeros(biases_select.shape)

    for i in range(t):
        time_step = t - 1 - i

        # Get important states
        prediction_t = predictions[time_step]
        pre_select_t = pre_select[time_step]
        pre_remember_t = pre_remember[time_step]
        pre_in_gate_t = pre_in_gate[time_step]
        pre_forget_t = pre_forget[time_step]
        forget_t = forget[time_step]
        input_and_output_t = input_and_output[time_step]
        state_current = state_added[time_step]

        if(time_step == 0):
            state_previous = np.zeros((self.output_size, true_t.shape[1]))
        else:
            state_previous = state_added[time_step - 1]

        # Calculate derivatives
        # First, sort out dh_t
        true_t = Y[time_step]

        # Initialise dc_t if not already done
        if(time_step == t - 1):
            dh_t = -2/(t * prediction_t.shape[0]) * (true_t - prediction_t)
            dc_t = dh_t * self.sigmoid(pre_select_t)

        # Calculate remember gate gradient
        dr = dc_t
        dp_r = dr * self.sigmoid(pre_select_t) * self.tanh_prime(pre_remember_t)
        dWr = dWr + np.dot(dp_r, input_and_output_t.T)
        dbr = dbr + np.sum(dp_r, axis=1, keepdims=True)

        # Calculate input gate gradient
        dp_i = dr * np.tanh(pre_remember_t) * self.sigmoid_prime(pre_in_gate_t)
        dWi = dWi + np.dot(dp_i, input_and_output_t.T)
        dbi = dbi + np.sum(dp_i, axis=1, keepdims=True)

        # Calculate forget gate gradient
        df = dc_t * state_previous
        dp_f = df * self.sigmoid_prime(pre_forget_t)
        dWf = dWf + np.dot(dp_f, input_and_output_t.T)
        dbf = dbf + np.sum(dp_f, axis=1, keepdims=True)

        dp_s = dh_t * np.tanh(state_current) * self.sigmoid_prime(pre_select_t)
        dWs = dWs + np.dot(dp_s, input_and_output_t.T)
        dbs = dbs + np.sum(dp_s, axis=1, keepdims=True)

        # Update dc_t
        dc_t = dc_t * forget_t

        # Update dh_t
        dh_t = np.dot(self.parameters["weights_select"].T, dp_s)
        dh_t = dh_t[0:self.output_size, :]

    # Compile all gradients into one dictionary
    grads = {}

    grads["weights_forget"] = dWf
    grads["weights_in_gate"] = dWi
    grads["weights_remember"] = dWr
    grads["weights_select"] = dWs

    grads["biases_forget"] = dbf
    grads["biases_in_gate"] = dbi
    grads["biases_remember"] = dbr
    grads["biases_select"] = dbs

    return grads
